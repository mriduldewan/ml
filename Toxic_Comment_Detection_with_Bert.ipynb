{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a text classification pipeline using the pre-trained BERT model for toxic comment classification. Here's a breakdown of the steps:\n",
    "- The necessary classes and functions are imported from the transformers library, including BertForSequenceClassification, BertTokenizer, and TextClassificationPipeline.\n",
    "- The path to the pre-trained BERT model for toxic comment classification is specified in the model_path variable.\n",
    "- The pre-trained BERT tokenizer is loaded from the specified model path using BertTokenizer.from_pretrained(model_path). The tokenizer is responsible for converting text input into numerical representations that the BERT model can understand.\n",
    "- The pre-trained BERT model for sequence classification is loaded from the specified model path using BertForSequenceClassification.from_pretrained(model_path, num_labels=2). The num_labels=2 parameter indicates that this is a binary classification task (toxic or non-toxic).\n",
    "- A TextClassificationPipeline is created using the loaded model and tokenizer. This pipeline simplifies the process of text classification by combining the tokenization, model inference, and output formatting steps into a single interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary classes and functions from the transformers library\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, TextClassificationPipeline\n",
    "\n",
    "# Path to the pre-trained BERT model for toxic comment classification\n",
    "model_path = \"JungleLee/bert-toxic-comment-classification\"\n",
    "\n",
    "# Load the pre-trained BERT tokenizer from the specified model path\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification from the specified model path\n",
    "# Set the number of labels to 2 (binary classification: toxic or non-toxic)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# Create a text classification pipeline using the loaded model and tokenizer\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    \"You're an idiot! Your ideas are completely stupid and make no sense.\",\n",
    "    \"I respectfully disagree with your opinion on this matter. Let's have a constructive discussion.\",\n",
    "    \"That's a ridiculous suggestion. You clearly have no idea what you're talking about.\",\n",
    "    \"I appreciate your perspective, but I have a different viewpoint on this issue.\",\n",
    "    \"Your argument is flawed and based on false assumptions. Do your research before spreading misinformation.\",\n",
    "    \"While I understand your concerns, I believe there are more positive ways to approach this problem.\",\n",
    "    \"You're a complete moron, and your ignorance is astounding. Get lost!\",\n",
    "    \"I'm open to hearing different opinions, but let's keep the conversation civil and respectful.\",\n",
    "    \"Your proposal is utter garbage, and you should be ashamed of yourself for even suggesting it.\",\n",
    "    \"I can see where you're coming from, but I think we need to consider all angles before making a decision.\",\n",
    "    \"John Doe is a sexist and racist teacher and has been like that the entire term.\"\n",
    "] \n",
    "\n",
    "results = pipeline(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input #1: You're an idiot! Your ideas are completely stupid and make no sense.\n",
      "Outcome : toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #2: I respectfully disagree with your opinion on this matter. Let's have a constructive discussion.\n",
      "Outcome : non-toxic\n",
      "Probability : 99.97%\n",
      "\n",
      "Input #3: That's a ridiculous suggestion. You clearly have no idea what you're talking about.\n",
      "Outcome : toxic\n",
      "Probability : 99.80%\n",
      "\n",
      "Input #4: I appreciate your perspective, but I have a different viewpoint on this issue.\n",
      "Outcome : non-toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #5: Your argument is flawed and based on false assumptions. Do your research before spreading misinformation.\n",
      "Outcome : non-toxic\n",
      "Probability : 91.89%\n",
      "\n",
      "Input #6: While I understand your concerns, I believe there are more positive ways to approach this problem.\n",
      "Outcome : non-toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #7: You're a complete moron, and your ignorance is astounding. Get lost!\n",
      "Outcome : toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #8: I'm open to hearing different opinions, but let's keep the conversation civil and respectful.\n",
      "Outcome : non-toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #9: Your proposal is utter garbage, and you should be ashamed of yourself for even suggesting it.\n",
      "Outcome : toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #10: I can see where you're coming from, but I think we need to consider all angles before making a decision.\n",
      "Outcome : non-toxic\n",
      "Probability : 99.98%\n",
      "\n",
      "Input #11: John Doe is a sexist and racist teacher and has been like that the entire term.\n",
      "Outcome : toxic\n",
      "Probability : 99.97%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for row in results:\n",
    "    print(f\"Input #{i+1}: {input_text[i]}\")\n",
    "    print(f\"Outcome : {row['label']}\")\n",
    "    print(f\"Probability : {row['score']*100:.2f}%\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
