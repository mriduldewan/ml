{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb7dfd83",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "This notebook explores Named Entity Recognition (NER) and entity masking techniques for text data. We leverage a pre-trained Bidirectional Encoder Representations from Transformers (BERT) model fine-tuned for NER tasks. The code achieves the following:\n",
    "\n",
    "- Data Preparation: Loads a sample DataFrame containing comments (text) and defines a dictionary to map NER tag prefixes (\"B-\" or \"I-\") to corresponding entity types (e.g., \"Person\", \"Location\").\n",
    "- NER Pipeline Creation: Creates an NER pipeline using the transformers library and a pre-trained BERT model specifically designed for NER.\n",
    "- NER Module: Implements an NERModule class to handle NER tasks:\n",
    "    - get_ner retrieves entity predictions for a given text.\n",
    "    - join_entities combines entities potentially broken down during model predictions.\n",
    "    - replace_entities replaces identified entities with placeholders based on their types (optional masking).\n",
    "    - mask_entities applies NER, creates a new column with masked text, and optionally removes intermediate columns.\n",
    "- Entity Masking: Applies NER to the comments in the DataFrame, replaces named entities with generic placeholders based on their types (configurable masking options), and creates a new column containing the masked text.\n",
    "- Sample Output: Demonstrates the code's functionality by printing an original comment and its masked version.\n",
    "\n",
    "This approach allows for identification and masking of named entities (people, locations, organizations, etc.) within text data, potentially protecting privacy or focusing on the sentiment of the text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6116b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd5b70",
   "metadata": {},
   "source": [
    "The output of the model would be words along with the type of entities. These are the different codes in use:\n",
    "- B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
    "- B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
    "- B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
    "- B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "697b7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to manage the entity types that could come up\n",
    "dict_entities = {\"I-PER\": \"Person\", \n",
    "                 \"B-PER\": \"Person\", \n",
    "                 \"I-ORG\": \"Organisation\",\n",
    "                 \"B-ORG\": \"Organisation\",\n",
    "                 \"I-LOC\": \"Location\",\n",
    "                 \"B-LOC\": \"Location\",\n",
    "                 \"I-MISC\": \"Miscellaneous\",\n",
    "                 \"B-MISC\": \"Miscellaneous\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63565a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataframe to pass to the model\n",
    "data = [\n",
    "    'Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:',\n",
    "    'Recession hit Veronique Branquinho, she has to quit her company, such a shame!',\n",
    "    'It is 2023 now. Sarah, Sharon, along with Margot Robbie, work at TFINA LTD and work from Ultimo in Kawandalama',\n",
    "    'Angola',\n",
    "    'that`s great!! weee!! visitors!',\n",
    "    'Antigua and Barbuda',\n",
    "    'I think everyone hates this dude lol. they are more like that dictator who seems to be ranting about almost everything now. He is from Wakanda'\n",
    "]\n",
    "\n",
    "# Create the pandas DataFrame with column name is provided explicitly\n",
    "df = pd.DataFrame(data, columns=['Comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0582b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_pipeline:\n",
    " \n",
    "    def __init__(self, task, model):\n",
    "        self.task = task\n",
    "        self.model = model\n",
    "\n",
    "    def create_classifier(self):\n",
    "        # Import the pipeline\n",
    "        from transformers import pipeline\n",
    "\n",
    "        return pipeline(task=self.task, model=self.model)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NER Module Class: Encapsulates NER-related functionality.\n",
    "\n",
    "- get_ner: extracts entity predictions for a given text.\n",
    "- join_entities: handles entity merging based on model-specific tokenization.\n",
    "- replace_entities: replaces entities with generic NER placeholders.\n",
    "- mask_entities: applies NER, creates a masked text column.\n",
    "\"\"\"\n",
    "class NERModule:\n",
    "\n",
    "    def __init__(self, classifier, df, colname):\n",
    "        self.classifier = classifier\n",
    "        self.df = df\n",
    "        self.col = colname   \n",
    "\n",
    "\n",
    "    def get_ner(self, text):\n",
    "        # Predict the NER tags\n",
    "        preds = self.classifier(text)\n",
    "        # Format the data as per the requirement\n",
    "        preds = [\n",
    "                {\n",
    "                    \"entity\": pred[\"entity\"],\n",
    "                    \"score\": round(pred[\"score\"], 4),\n",
    "                    \"index\": pred[\"index\"],\n",
    "                    \"word\": pred[\"word\"],\n",
    "                    \"start\": pred[\"start\"],\n",
    "                    \"end\": pred[\"end\"],\n",
    "                }\n",
    "                for pred in preds\n",
    "        ]\n",
    "        # Join the words that were together in the original text (separated by hash in entity recognition)\n",
    "        preds = self.join_entities(preds)\n",
    "        return preds\n",
    "\n",
    "\n",
    "    # Function to join the words that were broken down with # as the key in front of them during the entity recognition by the model\n",
    "    def join_entities(self, preds):\n",
    "        # Join the separated words together as per the input text\n",
    "        res = [] # Result list\n",
    "        i=0 # initial number to start the loop\n",
    "\n",
    "        while i < len(preds):\n",
    "            # Get the current row\n",
    "            currentrow = preds[i]\n",
    "\n",
    "            # If i is at the last line, add to result and break\n",
    "            if i == len(preds)-1:\n",
    "                res.append(currentrow)        \n",
    "                break\n",
    "\n",
    "            # Run a loop for all subsequent rows\n",
    "            for j in range(i+1, len(preds)):\n",
    "                # Get the content of the next row\n",
    "                nextrow = preds[j]\n",
    "\n",
    "                if np.float64(currentrow['end'])==np.float64(nextrow['start']):                              \n",
    "                    # Update current row end index to the next row end index\n",
    "                    currentrow['end'] = nextrow['end'] \n",
    "\n",
    "                    # Update current row word to concat with the next row word. Remember to remove any ## if they exist\n",
    "                    nextrow['word'] = nextrow['word'].replace(\"##\",\"\")\n",
    "                    currentrow['word'] = currentrow['word'] + nextrow['word'] \n",
    "\n",
    "                    # If J has reached the end, add the current row to the result and break\n",
    "                    if j == len(preds)-1:\n",
    "                        # Append to result\n",
    "                        res.append(currentrow)\n",
    "                        # Set i such that it breaks the outer loop\n",
    "                        i = len(preds)\n",
    "                        break\n",
    "                else:\n",
    "                    # Append the row to the result list\n",
    "                    res.append(currentrow)\n",
    "                    # Change the order to i to match j for the next loop\n",
    "                    i = j\n",
    "                    # Break the nested for loop\n",
    "                    break\n",
    "        return res\n",
    "\n",
    "\n",
    "\n",
    "    # Clean the string by removing entities\n",
    "    def replace_entities(self, text, entities, mask_name, mask_place, mask_org, mask_misc):\n",
    "        # If there is nothing in entities, then return the original text\n",
    "        if len(entities)==0:\n",
    "            cleaned = text\n",
    "        else:\n",
    "            # Sort the entities by start location to make replacement easier\n",
    "            entities.sort(key=lambda row: (row['start']), reverse=True)\n",
    "            #entities = sorted(df['entities'][0], key=lambda row: (row['start']), reverse=True)\n",
    "\n",
    "            # Convert the text to list\n",
    "            text_list = list(text)\n",
    "\n",
    "            # Loop through the entities\n",
    "            for entity in entities:\n",
    "                # Get start index\n",
    "                start = entity['start']\n",
    "                end = entity['end']\n",
    "                entity_type = entity['entity']\n",
    "\n",
    "                # Set term to replace\n",
    "                replacement = \"\"\n",
    "                if \"PER\" in entity_type:\n",
    "                    if mask_name:\n",
    "                        replacement = \"<name>\"\n",
    "                    \n",
    "                elif \"LOC\" in entity_type and mask_place:\n",
    "                    if mask_place:\n",
    "                        replacement = \"<place>\"\n",
    "                elif \"ORG\" in entity_type and mask_org:\n",
    "                    if mask_org:\n",
    "                        replacement = \"<organisation>\"\n",
    "                else:\n",
    "                    if mask_misc:\n",
    "                        replacement = \"<misc>\"\n",
    "\n",
    "                # Check if length of replacement is 0. If so, then skip replacement\n",
    "                if len(replacement)==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    # Replace the start position by generic term\n",
    "                    text_list[start] = replacement\n",
    "\n",
    "                    # Remove the remaining characters to the end of the original word\n",
    "                    del text_list[start+1:end]\n",
    "\n",
    "                # Join back the string and return\n",
    "                cleaned = ''.join(text_list)\n",
    "        \n",
    "        return cleaned\n",
    "\n",
    "\n",
    "    def mask_entities(self, delete_ner_tags=True, mask_name=True, mask_place=True, mask_org=True, mask_misc=True):\n",
    "\n",
    "        # Create a lambda function to get the NER tags from the given col of the dataframe\n",
    "        self.df['entities'] = self.df[self.col].apply(lambda x: self.get_ner(x))\n",
    "\n",
    "        # Replace text with NER tags\n",
    "        self.df['masked'] = self.df.apply(lambda x: self.replace_entities(x[self.col], x['entities'], mask_name=True, mask_place=True, mask_org=True, mask_misc=True), axis=1)\n",
    "\n",
    "        # If the delete_ner_tags attribute is True, then drop the entities column\n",
    "        if delete_ner_tags:\n",
    "            self.df.drop('entities', axis=1, inplace=True)\n",
    "\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64730c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an NER pipeline using a pre-trained BERT model specifically fine-tuned for NER.\n",
    "classifier = classifier_pipeline('ner', 'dbmdz/bert-large-cased-finetuned-conll03-english').create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18beffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NERModule object\n",
    "ner = NERModule(classifier, df, 'Comments')\n",
    "\n",
    "# Call the mask_entities method to perform NER, mask entities with placeholders, and create a new column with the masked text\n",
    "df = ner.mask_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ceeced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original statement: It is 2023 now. Sarah, Sharon, along with Margot Robbie, work at TFINA LTD and work from Ultimo in Kawandalama \n",
      "  Masked statement: It is 2023 now. <name>, <name>, along with <name> <name>, work at <organisation> <organisation> and work from <organisation> in <place>\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "index = 2 # Starts at 0\n",
    "\n",
    "print(f\"Original statement: {df['Comments'][index]} \\n  Masked statement: {df['masked'][index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
