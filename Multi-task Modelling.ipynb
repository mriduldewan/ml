{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task modelling\n",
    "\n",
    "The key components of this multi-task learning implementation:\n",
    "\n",
    "1. Model Architecture\n",
    "   \n",
    "- The model uses BERT as a shared backbone\n",
    "- It has two task-specific heads:\n",
    "    - Sentiment classifier (multi-class: positive/neutral/negative with configurable neutral thresholds)\n",
    "    - Topic classifier (multi-class)\n",
    "- The shared layers learn common features useful for both tasks  \n",
    "<br>\n",
    "2. Key Components:\n",
    "\n",
    "- TextDataset: Handles data preprocessing and tokenization\n",
    "- MultitaskModel: The main model combining both tasks\n",
    "- Training loop with combined loss function  \n",
    "\n",
    "<br>\n",
    "3. Loss Function:\n",
    "\n",
    "- Uses separate loss functions for each task\n",
    "- Combines them into a total loss for optimization  \n",
    "\n",
    "<br>\n",
    "4. Benefits of Multi-task Learning:\n",
    "\n",
    "- Shared representation learning\n",
    "- Better generalization\n",
    "- More efficient use of data\n",
    "- Reduced overfitting through regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, sentiment_labels, topic_labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.sentiment_labels = sentiment_labels  # Now 0: negative, 1: neutral, 2: positive\n",
    "        self.topic_labels = topic_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sentiment_label': torch.tensor(self.sentiment_labels[idx], dtype=torch.long),\n",
    "            'topic_label': torch.tensor(self.topic_labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class MultitaskModel(nn.Module):\n",
    "    def __init__(self, num_topics, num_sentiments=3):  # Changed to 3 sentiments\n",
    "        super(MultitaskModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Shared layers\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Task-specific layers\n",
    "        self.sentiment_classifier = nn.Linear(hidden_size, num_sentiments)\n",
    "        self.topic_classifier = nn.Linear(hidden_size, num_topics)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Task-specific predictions\n",
    "        sentiment_logits = self.sentiment_classifier(pooled_output)\n",
    "        topic_logits = self.topic_classifier(pooled_output)\n",
    "        \n",
    "        return sentiment_logits, topic_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(texts, sentiment_labels, topic_labels, num_topics, num_epochs=3):\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = MultitaskModel(num_topics=num_topics, num_sentiments=3)  # Changed to 3 sentiments\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = TextDataset(texts, sentiment_labels, topic_labels, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Loss functions\n",
    "    sentiment_criterion = nn.CrossEntropyLoss()\n",
    "    topic_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            sentiment_labels = batch['sentiment_label']\n",
    "            topic_labels = batch['topic_label']\n",
    "            \n",
    "            sentiment_logits, topic_logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            sentiment_loss = sentiment_criterion(sentiment_logits, sentiment_labels)\n",
    "            topic_loss = topic_criterion(topic_logits, topic_labels)\n",
    "            total_loss = sentiment_loss + topic_loss\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss.item():.4f}\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, text, topic_names=None, neutral_thresholds=(0.4, 0.6)):\n",
    "    \"\"\"\n",
    "    Make predictions for a new text input.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MultitaskModel\n",
    "        tokenizer: BERT tokenizer\n",
    "        text: Input text string\n",
    "        topic_names: Optional list of topic names for readable output\n",
    "        neutral_thresholds: Tuple of (lower, upper) thresholds for neutral sentiment\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing sentiment and topic predictions\n",
    "    \"\"\"\n",
    "    # Prepare the model for evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        sentiment_logits, topic_logits = model(\n",
    "            encoding['input_ids'],\n",
    "            encoding['attention_mask']\n",
    "        )\n",
    "        \n",
    "        # Get predictions\n",
    "        sentiment_probs = torch.softmax(sentiment_logits, dim=1)[0]\n",
    "        topic_pred = torch.softmax(topic_logits, dim=1)[0]\n",
    "        \n",
    "        # Determine sentiment based on probabilities and thresholds\n",
    "        sentiment_label = sentiment_probs.argmax().item()\n",
    "        sentiment_confidence = float(sentiment_probs[sentiment_label])\n",
    "        \n",
    "        # Map numerical labels to text labels\n",
    "        sentiment_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "        sentiment_text = sentiment_map[sentiment_label]\n",
    "        \n",
    "        topic_label = topic_pred.argmax().item()\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'text': text,\n",
    "        'sentiment': {\n",
    "            'label': sentiment_text,\n",
    "            'confidence': sentiment_confidence,\n",
    "            'probabilities': {\n",
    "                'negative': float(sentiment_probs[0]),\n",
    "                'neutral': float(sentiment_probs[1]),\n",
    "                'positive': float(sentiment_probs[2])\n",
    "            }\n",
    "        },\n",
    "        'topic': {\n",
    "            'label': topic_names[topic_label] if topic_names else f\"Topic {topic_label}\",\n",
    "            'confidence': float(topic_pred[topic_label])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 2.0385\n",
      "Epoch 2/3, Loss: 2.3136\n",
      "Epoch 3/3, Loss: 2.4543\n",
      "\n",
      "Prediction Results:\n",
      "Text: The new AI features in this product are revolutionary!\n",
      "Sentiment: Neutral (Confidence: 0.39)\n",
      "Sentiment Probabilities:\n",
      "  Negative: 0.24\n",
      "  Neutral: 0.39\n",
      "  Positive: 0.37\n",
      "Topic: Product (Confidence: 0.38)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "# In reality, this dataset will be imported, cleaned, and transformed. \n",
    "# Typically this will be followed by a train/val/test split prior to calling\n",
    "# the train_model function\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Training data\n",
    "    texts = [\n",
    "        \"This product is amazing and works great!\",\n",
    "        \"The service was terrible and disappointing.\",\n",
    "        \"The product works as expected.\",\n",
    "        \"The market outlook remains negative.\",\n",
    "        \"This is okay, nothing special.\"\n",
    "    ]\n",
    "    # 0: negative, 1: neutral, 2: positive\n",
    "    sentiment_labels = [2, 0, 1, 0, 1]  \n",
    "    topic_labels = [2, 1, 0, 3, 2]      # Example topics: 0: Technology, 1: Service, 2: Product, 3: Finance\n",
    "    \n",
    "    # Train the model\n",
    "    topic_names = ['Technology', 'Service', 'Product', 'Finance']\n",
    "    model, tokenizer = train_model(texts, sentiment_labels, topic_labels, num_topics=len(topic_names))\n",
    "    \n",
    "    # Make predictions for new text\n",
    "    new_text = \"The new AI features in this product are mindblowing!\"\n",
    "    predictions = predict(model, tokenizer, new_text, topic_names, neutral_thresholds=(0.4, 0.6))\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(f\"Text: {predictions['text']}\")\n",
    "    print(f\"Sentiment: {predictions['sentiment']['label']} \"\n",
    "          f\"(Confidence: {predictions['sentiment']['confidence']:.2f})\")\n",
    "    print(\"Sentiment Probabilities:\")\n",
    "    for sentiment, prob in predictions['sentiment']['probabilities'].items():\n",
    "        print(f\"  {sentiment.capitalize()}: {prob:.2f}\")\n",
    "    print(f\"Topic: {predictions['topic']['label']} \"\n",
    "          f\"(Confidence: {predictions['topic']['confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Results:\n",
      "Text: The new AI features in this product are mindblowing!\n",
      "\n",
      "Sentiment: Positive (Confidence: 0.41)\n",
      "Sentiment Probabilities:\n",
      "  Negative: 0.21\n",
      "  Neutral: 0.39\n",
      "  Positive: 0.41\n",
      "\n",
      "Topic: Product (Confidence: 0.35)\n",
      "\n",
      "    ****  ****  ****  ****  ****  ****  ****  **** \n",
      "\n",
      "Prediction Results:\n",
      "Text: The markets will open higher today\n",
      "\n",
      "Sentiment: Neutral (Confidence: 0.41)\n",
      "Sentiment Probabilities:\n",
      "  Negative: 0.29\n",
      "  Neutral: 0.41\n",
      "  Positive: 0.30\n",
      "\n",
      "Topic: Product (Confidence: 0.34)\n",
      "\n",
      "    ****  ****  ****  ****  ****  ****  ****  **** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for new text\n",
    "new_text = [\"The new AI features in this product are mindblowing!\",\n",
    "            \"The markets will open higher today\"]\n",
    "\n",
    "for txt in new_text:\n",
    "      predictions = predict(model, tokenizer, txt, topic_names, neutral_thresholds=(0.4, 0.6))\n",
    "\n",
    "      # Print results\n",
    "      print(\"Prediction Results:\")\n",
    "      print(f\"Text: {predictions['text']}\\n\")\n",
    "      print(f\"Sentiment: {predictions['sentiment']['label']} \"\n",
    "            f\"(Confidence: {predictions['sentiment']['confidence']:.2f})\")\n",
    "      print(\"Sentiment Probabilities:\")\n",
    "      for sentiment, prob in predictions['sentiment']['probabilities'].items():\n",
    "            print(f\"  {sentiment.capitalize()}: {prob:.2f}\")\n",
    "      print(f\"\\nTopic: {predictions['topic']['label']} \"\n",
    "            f\"(Confidence: {predictions['topic']['confidence']:.2f})\")\n",
    "      \n",
    "      print(\"\\n    ****  ****  ****  ****  ****  ****  ****  **** \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
